{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\rafra\\.conda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pre-procesado\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Aprendizaje por transferencia traemos la red MobileNetV2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Capas\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Optimizador\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "%matplotlib inline\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descomprimir el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Path\n",
    "dataset_path = \"../input/cats_and_dogs_filtered.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize as a zip file\n",
    "#zip_obj = zipfile.ZipFile(file=dataset_path, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip_obj.extractall(\"../input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar las rutas al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_new = '../input/cats_and_dogs_filtered/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_path_new, 'train')\n",
    "validation_dir = os.path.join(dataset_path_new, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar modelo pre entrenado (MobileNetV2)\n",
    "    Cargaremos un modelo preentrenado por google llamado MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametros**\n",
    "\n",
    "    * include_top : no incluye la fase final de la red neuronal entrenada, por tanto creare una cabezera personalizada indicando el tipo de clasificación que yo deseo.\n",
    "    * weights : elegimos 'imagenet' que es uno de los set de datos standar que utilizó para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congelar modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se congela la base que lleva la predicción en orden de personalizar nuetro modelo\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir la cabecera personalizada para nuestra red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'out_relu/Identity:0' shape=(None, 4, 4, 1280) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# podemos ver la capa de salida\n",
    "base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GlobalAveragePooling2D -> Capa Operación de agrupación promedio global para datos temporales.\n",
    "# De las 4X4 direcciones vamos a promediarlas\n",
    "global_average_layer = GlobalAveragePooling2D()(base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'global_average_pooling2d/Identity:0' shape=(None, 1280) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_average_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar los 1280 valores  a una unica unidad que sera una probabilidad  de una de nuestras clases\n",
    "prediction_layer = Dense(units=1, activation='sigmoid')(global_average_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinación de las dos redes neuronales & definción del modelo\n",
    "model = Model(inputs = base_model.input, outputs = prediction_layer)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordar que es un problema de \n",
    "model.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear Generadores de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Redimensionar imágenes**\n",
    "\n",
    "    Las grandes arquitecturas pre-entrenadas solamente soportan cierto tipo de tamaños de imágenes.\n",
    "    \n",
    "    Por ejemplo: MobileNet (la arquitectura que nosotros usamos) soporta: (96, 96), (128, 128), (160, 160), (192, 192), (224, 224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation.\n",
    "# The data will be looped over (in batches).\n",
    "data_gen_train = ImageDataGenerator(rescale=1/255.)\n",
    "data_gen_valid = ImageDataGenerator(rescale=1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# carga las imagenes sin aplanarlas\n",
    "train_generator = data_gen_train.flow_from_directory(train_dir, target_size=(128,128), batch_size=128, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = data_gen_valid.flow_from_directory(validation_dir, target_size=(128,128), batch_size=128, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate for 8 steps\n",
      "Epoch 1/8\n",
      "16/16 [==============================] - 98s 6s/step - loss: 0.6671 - accuracy: 0.6120 - val_loss: 0.8103 - val_accuracy: 0.5350\n",
      "Epoch 2/8\n",
      "16/16 [==============================] - 101s 6s/step - loss: 0.6093 - accuracy: 0.6610 - val_loss: 0.7175 - val_accuracy: 0.5790\n",
      "Epoch 3/8\n",
      "16/16 [==============================] - 101s 6s/step - loss: 0.5618 - accuracy: 0.7065 - val_loss: 0.6415 - val_accuracy: 0.6240\n",
      "Epoch 4/8\n",
      "16/16 [==============================] - 101s 6s/step - loss: 0.5205 - accuracy: 0.7445 - val_loss: 0.5772 - val_accuracy: 0.6970\n",
      "Epoch 5/8\n",
      "16/16 [==============================] - 90s 6s/step - loss: 0.4835 - accuracy: 0.7765 - val_loss: 0.5178 - val_accuracy: 0.7600\n",
      "Epoch 6/8\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.4504 - accuracy: 0.8060 - val_loss: 0.4638 - val_accuracy: 0.8040\n",
      "Epoch 7/8\n",
      "16/16 [==============================] - 105s 7s/step - loss: 0.4220 - accuracy: 0.8280 - val_loss: 0.4242 - val_accuracy: 0.8310\n",
      "Epoch 8/8\n",
      "16/16 [==============================] - 104s 6s/step - loss: 0.3962 - accuracy: 0.8480 - val_loss: 0.3874 - val_accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x254cd44e688>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=8, validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el modelo de aprendizaje por transferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.3874 - accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy afted transfer learning: 0.8550000190734863\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy afted transfer learning: {}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning : Puesta a punto de Parametros\n",
    "\n",
    "Un par de cosas:\n",
    "\n",
    "    **NUNCA HAY QUE USAR** la puesta a punto (fine tuning) de parámetros en toda la red neuronal: con algunas de las capas superiores (las finales) es más que suficiente suficiente. En la mayoría de casos, son las más especializadas. El objetivo del fine tuning es adaptar esa parte específica de la red neuronal para nuestro nuevo dataset específico.\n",
    "    **Empezar con la puesta a punto DESPUÉS de haber finalizado la fase de aprendizaje** por transferencia. Si intentamos hacer el Fine tuning inmediatamente, los gradientes serán muy diferentes entre nuestra cabecera personalizada de la red neuronal y las nuevas capas no congeladas del modelo base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model: 155\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: {}\".format(len(base_model.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a congelar desde la primera hasta la numero 100\n",
    "fine_tune_at = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por medio de este bucle\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate for 8 steps\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 115s 7s/step - loss: 0.1554 - accuracy: 0.9435 - val_loss: 0.0895 - val_accuracy: 0.9650\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 114s 7s/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 117s 7s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9630\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 101s 6s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9620\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 102s 6s/step - loss: 8.0328e-04 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9610\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 101s 6s/step - loss: 3.0395e-04 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9610\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 102s 6s/step - loss: 1.1974e-04 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9610\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 104s 6s/step - loss: 4.7779e-05 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9610\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 110s 7s/step - loss: 1.9731e-05 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9600\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 104s 6s/step - loss: 8.1838e-06 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x254d3cc00c8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo red-calibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.2522 - accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after fine tuning: 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation accuracy after fine tuning: {}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
